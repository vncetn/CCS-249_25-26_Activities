{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4745dbfe",
   "metadata": {},
   "source": [
    "# CCS-249 Exercise Unit 2: ELIZA and RegEx NLP\n",
    "\n",
    "## Exercise 1: Updating ELIZA\n",
    "Builds a chatbot that recognizes patterns using regex and responds to specific questions. Includes 5 emotional patterns and sarcastic responses for repeated questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Updating ELIZA\n",
    "import re\n",
    "import random\n",
    "\n",
    "def reflect(fragment):\n",
    "    \"\"\"Swap pronouns to reflect user input back to them.\"\"\"\n",
    "    reflections = {\n",
    "        \"am\": \"are\",\n",
    "        \"was\": \"were\",\n",
    "        \"i\": \"you\",\n",
    "        \"i'd\": \"you would\",\n",
    "        \"i've\": \"you have\",\n",
    "        \"i'll\": \"you will\",\n",
    "        \"my\": \"your\",\n",
    "        \"are\": \"am\",\n",
    "        \"you've\": \"I have\",\n",
    "        \"you'll\": \"I will\",\n",
    "        \"your\": \"my\",\n",
    "        \"yours\": \"mine\",\n",
    "        \"you\": \"me\",\n",
    "        \"me\": \"you\"\n",
    "    }\n",
    "    return ' '.join(reflections.get(word.lower(), word) for word in fragment.split())\n",
    "\n",
    "def eliza_response(user_input):\n",
    "    \"\"\"Generate ELIZA response based on pattern matching.\"\"\"\n",
    "    patterns = [\n",
    "        (r\"I need (.*)\", \"Why do you need {0}?\"),\n",
    "        (r\"Why don['']t you (.*)\", \"Do you really think I don't {0}?\"),\n",
    "        (r\"I feel (.*)\", \"Tell me more about feeling {0}.\"),\n",
    "        (r\"I want to know the reasons why I am feeling depressed all the time\\.?\",\n",
    "         \"Why do you want to know the reasons for feeling depressed all the time?\"),\n",
    "        (r\"I am feeling stressed\\.?\", \"Tell me more about why you're feeling stressed.\"),\n",
    "        (r\"My feelings towards my crush are invalidated\\.?\",\n",
    "         \"Why do you think your feelings towards your crush are invalidated?\"),\n",
    "        (r\"You (don['']t|do not) understand me\\.?\",\n",
    "         \"Why do you think I don't understand you?\"),\n",
    "        (r\"I (can['']t|cannot) focus on my studies\\.?\",\n",
    "         \"What is making it difficult for you to focus on your studies?\")\n",
    "    ]\n",
    "    \n",
    "    for pattern, response in patterns:\n",
    "        match = re.match(pattern, user_input, re.IGNORECASE)\n",
    "        if match and match.groups():\n",
    "            return response.format(reflect(match.group(1)))\n",
    "        elif match:\n",
    "            return response\n",
    "    return \"Tell me more about that.\"\n",
    "\n",
    "previous_questions = []\n",
    "sarcasm = [\n",
    "    \"We've been through this already. Try something new.\",\n",
    "    \"Seriously? Again? I thought we moved on.\",\n",
    "    \"Oh wow, you're stuck on that? Let's call it a day.\",\n",
    "    \"Asking me the same thing twice won't change anything.\",\n",
    "    \"What, did you forget I already answered that?\",\n",
    "    \"Congratulations, you've discovered the loop function.\",\n",
    "    \"I'm not a broken record, even if you're testing me.\"\n",
    "]\n",
    "\n",
    "print(\"ELIZA: Hello! How can I help you today?\")\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    \n",
    "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "        print(\"ELIZA: Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    if not user_input:\n",
    "        continue\n",
    "    \n",
    "    if user_input.lower() in [q.lower() for q in previous_questions]:\n",
    "        print(f\"ELIZA: {random.choice(sarcasm)}\\n\")\n",
    "    else:\n",
    "        response = eliza_response(user_input)\n",
    "        print(f\"ELIZA: {response}\\n\")\n",
    "        previous_questions.append(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc02f8",
   "metadata": {},
   "source": [
    "## Exercise 2: Implementing RegEx on NLP\n",
    "Applies regex patterns to extract and process text data.\n",
    "\n",
    "### Part A: Extract Capitalized Words\n",
    "Use regex to find all words that start with a capital letter in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A: Extract words starting with uppercase\n",
    "import re\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"PART A: Extract Capitalized Words\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "text = \"\"\"Alice was beginning to get very tired of sitting by her sister on the bank,\n",
    "and of having nothing to do. Once or twice she had peeped into the book\n",
    "her sister was reading, but it had no pictures or conversations in it, \"and\n",
    "what is the use of a book,\" thought Alice, \"without pictures or conversations?\"\"\"\n",
    "\n",
    "pattern = r'\\b[A-Z]\\w*'\n",
    "words = re.findall(pattern, text)\n",
    "\n",
    "print(f\"Pattern: {pattern}\")\n",
    "print(f\"Capitalized words: {words}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a00af",
   "metadata": {},
   "source": [
    "### Part B: Extract and Replace from Literary Text\n",
    "Read Moby Dick text file and replace the first 10 instances of \"Whale/whale\" with \"leviathan\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e622904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B: Extract and replace Whale/whales in Moby Dick\n",
    "print(\"=\" * 50)\n",
    "print(\"PART B: Extract and Replace Whale/Whales\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    with open(r'c:\\Users\\DELL\\Desktop\\CCS-249_25-26_Activities\\BSCS 3A\\KYLA_ELIJAH_RAMIRO\\melville-moby_dick.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    pattern = r'\\b(Whale|Whales|whale|whales)\\b'\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    print(f\"Pattern: {pattern}\")\n",
    "    print(f\"Total matches: {len(matches)}\")\n",
    "    print(f\"First 10: {matches[:10]}\\n\")\n",
    "    \n",
    "    # Replace first 10 instances\n",
    "    counter = [0]\n",
    "    def replace_first_ten(m):\n",
    "        counter[0] += 1\n",
    "        return \"leviathan\" if counter[0] <= 10 else m.group(0)\n",
    "    \n",
    "    modified = re.sub(pattern, replace_first_ten, text)\n",
    "    print(f\"First 10 instances replaced with 'leviathan'\\n\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: melville-moby_dick.txt not found\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f4367",
   "metadata": {},
   "source": [
    "### Part C: Extract Character Dialogue from NLTK Corpus\n",
    "Use NLTK to load the pirates.txt file and extract all lines spoken by Jack Sparrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83906c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part C: Extract Jack Sparrow lines from NLTK Pirates corpus\n",
    "print(\"=\" * 50)\n",
    "print(\"PART C: Extract Jack Sparrow Dialogue\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.corpus import webtext\n",
    "    \n",
    "    nltk.download('webtext', quiet=True)\n",
    "    \n",
    "    text = webtext.raw('pirates.txt')\n",
    "    pattern = r'JACK SPARROW:\\s*(.+?)(?=\\n[A-Z\\s]+:|$)'\n",
    "    \n",
    "    lines = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    print(f\"Pattern: {pattern}\")\n",
    "    print(f\"Total Jack Sparrow lines: {len(lines)}\\n\")\n",
    "    print(\"First 5 lines:\")\n",
    "    for i, line in enumerate(lines[:5], 1):\n",
    "        clean = line.strip().replace('\\n', ' ')[:80]\n",
    "        print(f\"{i}. {clean}...\\n\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Error: NLTK not installed. Run: pip install nltk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
